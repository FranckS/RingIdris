\section{Introduction}

Proofs assistants like Coq(ref), Agda(ref) and Idris(ref) are based on Intensional Type Theories, that contain two notions of equality. One is the equality that can be manipulated in the language, called the propositional equality. This equality corresponds to the equality found in mathematics : this is a proposition that can be assumed, negated, proved or disproved. Since in type theory, propositions are seen as types~\cite{How80}, the
proposition that two elements $x$ and $y$ are equal corresponds to a type.
If $x$ and $y$ are of type $a$, then the type
$Id_a(x, y)$ represents the proposition ``$x$ is equal to $y$". If this type is
inhabited, then $x$ is said to be provably equal to $y$. Thus, $Id$ is a type family (parametrised by the type $a$) indexed over two elements of $a$, giving $Id (a:Type)\ :\ a \rightarrow a \rightarrow Type$. For
convenience, we write $(Id_a\ x\ y)$ as $(x\ =_a\ y)$. 

The second notion of equality in Intentional Type Theories is a primitive concept, called judgemental equality, or definitional equality. This second equality means ``equal by definition''. The judgemental equality cannot be negated or assumed; we cannot talk about this primitive equality inside the theory.
Whether or not two expressions are equal by definition is a matter of
evaluating the definitions. For example, if $f\ :\ \mathbb{N}\ \rightarrow\
\mathbb{N}$ is defined by $f\ x\ :=\ x\ +\ 2$, then $f\ 5$ is
definitionally equal to $7$. Definitional equality entails unfolding
of functions and reductions, until no more reduction can be
performed. We denote the definitional equality by $\equiv$.

The judgemental equality has to be included in the propositional equality, because what is equal by definition should be provably equal. This is accomplished by giving constructors to the type $Id(a,a)$ and nothing when ``$a$ is not $b$".
In these theories, $Id$ is therefore implemented with the following sum type that has only one constructor :

\begin{lstlisting}
data Id : a $\rightarrow$ a $\rightarrow$ Type where
     Refl : (x : a) $\rightarrow$ Id x x
\end{lstlisting}

The only way for $(Id_a\ x\ y)$ to be inhabited is therefore that $x$ should be
(by definition) $y$. In this case, the constructor $Refl$ helps to create a
proof of this equality : $(Refl\ x)$ is precisely the proof which says that
$x=_ax$. 

When reading these definitions, one could wrongly think that the propositional equality is a simple wrapper of the judgemental equality. This is not the case : the propositional equality does not only contain the judgemental equality, because in these type theories, a principle of induction is associated with each inductive type. If a type $T$ is an inductive type with a constant constructor and a recursive constructor, ie, $T = 1 + T$, defined in idris as : 

\begin{lstlisting}
data T : Type where
  T0 : T
  T1 : T $\rightarrow$ T          
\end{lstlisting}

then we have : \\
$T\_ind : \forall P:T \rightarrow Type,\ (P\ T0) \rightarrow (\forall t:T,\ P\ t \rightarrow P\ (T1\ t)) \rightarrow (\forall t:T,\ P\ t)$.

The principles of induction can be used for proving any proposition $P$, so they also work for the propositional equality. For example, we can prove that $n+0 = n$ for all $n$ by induction on the $Nat\ n$, even if $n+0 \not\equiv n$ with the usual definition of $+$, recursive on its first argument. That means that the axiom of induction has made the type $Id_{a}(x,y)$ bigger than it looks like : it contains terms that are not generated by $Refl$ (the only constructor of $Id_{a}(x,y)$), but that are added by the inductive principles. There are therefore things which are provably equal which unfortunately are not definitionally equal after unfolding all the definitions and after full reductions. The activity of proving equalities is therefore in these theories something which isn't automatically decidable by the type-checker in the very general case.

Proving that one term is equal to another is quite common
in formal certification. This is an everyday routine when working in a dependently typed language, and especially when intensively indexing types over values in order to capture some logical properties, as we will show in the following subsection.

\subsection{Motivating example: Verified Binary Arithmetic}
\label{sect:motivatingExample}

We revisit an example from a previous work of Edwin Brady~\cite{bradytfp07} which shows how proof obligations may arise when a type is indexed by natural numbers. In this development, the goal is to implement a formally verified library of binary numbers. In order to ensure the correctness of the methods that will be developed, we define the types $Bit$ and $Binary$ as indexed over the value they represent (expressed as a natural number), following a correct-by-construction approach.

\begin{lstlisting}
data Bit : Nat $\rightarrow$ Type where
     b0 : Bit Z
     b1 : Bit (S Z)
     
data Binary : (width : Nat) $\rightarrow$ (value : Nat) $\rightarrow$ Type where
     zero : Binary Z Z
     (#) : Binary w v $\rightarrow$ Bit bit $\rightarrow$ Binary (S w) (bit + 2 * v)
\end{lstlisting}

We want to write a function performing the addition between two binary numbers. In order to do so, we start with an auxiliary function, which adds three bits
(the third one plays the role of a carry flag), and produces the two bits of
the result, where the first one is the most significant bit. 

\begin{lstlisting}
addBit : Bit x $\rightarrow$ Bit y $\rightarrow$ Bit c $\rightarrow$ (bX ** (bY ** 
         (Bit bX, Bit bY, c + x + y = bY + 2 * bX)))
addBit b0 b0 b0 = (_ ** (_ ** (b0, b0, Refl)))
addBit b0 b0 b1 = (_ ** (_ ** (b0, b1, Refl)))
addBit b0 b1 b0 = (_ ** (_ ** (b0, b1, Refl)))
addBit b0 b1 b1 = (_ ** (_ ** (b1, b0, Refl)))
addBit b1 b0 b0 = (_ ** (_ ** (b0, b1, Refl)))
addBit b1 b0 b1 = (_ ** (_ ** (b1, b0, Refl)))
addBit b1 b1 b0 = (_ ** (_ ** (b1, b0, Refl)))
addBit b1 b1 b1 = (_ ** (_ ** (b1, b1, Refl)))
\end{lstlisting}

This function produces a dependent pair. The first component is the value $bX$ (expressed as a natural number) representing the first bit produced (therefore of type $Bit\ bX$), and the second component is another dependent pair. This second dependent pair is composed of the value $bY$ representing the second bit produced, and of a triple containing the two bits produced and a proof that these two bits correctly encode the result of the addition.
For example, on the fifth line, which corresponds to the computation $1_2 + 0_2 + 0_2 = (01)_2$, the function produces the bit $b0$ (encoding $0_2$) and the bit $b1$ (encoding $1_2$), and a proof that $1 + 0 + 0 = 1 + (2*0)$.

We finally define the function $adc$ that adds two binary numbers and a carry flag. This addition works for two binary numbers expressed with the same number of bits, and it produces a result with one more bit. This result represents the sum of the three concrete values of the inputs. Therefore, we want to write :

\begin{lstlisting}
adc : Binary w x $\rightarrow$ Binary w y $\rightarrow$ Bit c $\rightarrow$ Binary (S w) (c + x + y)
adc zero zero carry = zero # carry
adc (numx # bX) (numy # bY) carry
  = let (vCarry0 ** (vLsb ** (carry0, lsb, _))) = addBit bX bY carry in
          adc numx numy carry0 # lsb
\end{lstlisting}

Unfortunately, this straightforward definition is rejected by Idris' type-checker because the types mismatch for both of the two patterns. The result of the first line $adc\ zero\ zero\ carry$ is expected to have the type $Binary\ 1\ (plus\ (plus\ c\ 0)\ 0)$ but we provide a term of type $Binary\ 1\ (plus\ c\ (plus\ 0\ (plus\ 0\ 0)))$.
The problem is even worse for the second case where the expected index is \\
$(plus\ (plus\ c\ (plus\ bit2\ (plus\ v1\ (plus\ v1\ 0))))\ (plus\ bit\ (plus\ v\ (plus\ v\ 0))))$
while we're trying to provide a term indexed over \\
$plus\ vLsb\ (plus\ (plus\ (plus\ vCarry0\ v1)\ v)\ (plus\ (plus\ (plus\ vCarry0\ v1)\ v)\ 0))$.
We know that the definition of $adc$ we have given is correct, and it has \emph{provably} the expected type, but it does not have it \emph{immediately} or \emph{by reduction} : after full reductions\footnote{In dependently typed theories, the presence of types predicated on values creates the need of using reductions also inside of types}, the expected and provided types are still different, and Idris can not figure out a proof of compatibility on its own. 
If we use provisional definitions[ref], the previous definition can be accepted by the system, but we now have two proof obligations $adc\_lemma\_1$ and $adc\_lemma\_2$ demanding proofs of equality between the two types, and they have to be provided by hand --here with a proof script-- :

\begin{lstlisting}
adc_lemma_2 = proof {
    intros;
    rewrite sym (plusZeroRightNeutral x);
    [...]
    rewrite sym (plusAssociative (plus c (plus bit0 (plus v v))) 
                 bit1 (plus v1 v1));
    rewrite (plusAssociative c (plus bit0 (plus v v)) bit1);
    rewrite plusCommutative bit1 (plus v v);
    [...]
    rewrite (plusAssociative (plus (plus x v) v1) (plus x v) v1);
    trivial;
}
\end{lstlisting}

As we see, this kind of proof consists of a potentially long sequence of rewriting steps, where each step uses one of the available properties: neutral element, commutativity, associativity. Without some specific automation, this sequence of rewriting must be done by the programmer.
This is time consuming and more importantly, just a small change in the left or the right hand side of the equality may invalidate the proof. That means that a minor change in our datatypes, or in the definition of $addBit$ or $adc$ will require us to replace this proof by another one fulfilling the same task.
These proofs become the everyday routine in any dependently-typed language, as soon as we index types over values in order to capture some logical properties.  

The proof that we have written by hand only uses the existence of neutral elements, and the associativity and commutativity of $+$ on $Nat$. Thus, we're rewriting a term by using the properties of a commutative monoid. We would like to let a generic prover for commutative monoid find a proof on its own.

\subsection{Our contributions}

Ring solvers are already implemented for various proof
assistants, including Coq~\cite{Coq2005} and Agda\footnote{\url{http://wiki.portal.chalmers.se/agda/\%22?n=Libraries.UsingTheRingSolver}}. 
In this paper, we describe a certified
implementation\footnote{The implementation of our hierarchy of tactics can be found online at \url{https://github.com/FranckS/RingIdris}} of an automatic prover for equalities in a \emph{hierarchy} of algebraic
structures, including Monoid, Groups and Rings (all potentially commutative),
for the Idris language. 

The principal novelty is in the approach that we follow, using a
new kind of \emph{type-safe reflection}.  Working by reflection for implementing tactics has been done several times, including for the implementation of a ring solver for the Coq proof assistant, but without the type-safe aspect. We will
compare our approach with other implementations in Section~\ref{sect:AlternativeApproaches}.

The contributions of this paper are the following :

\begin{enumerate}

\item We present a new type-safe reflection mechanism, where the reflected terms are indexed over the concrete inputs, thus providing a
direct way to pull out the proofs, and providing the guarantee that the reflection of a term is indeed a faithful representation of the term.
The basic ideas of the technique are first presented in Section~\ref{sect:aSimpleProofAutomation} on a smaller problem with only natural numbers and addition, and are later adapted for a hierarchy of tactics proving equalities in algebraic strcures, in Section~\ref{sect:ProvingEquivalencesInAlgebraicStructures}. 

\item The normalisation procedures are implemented by following a
correct by construction approach, instead of implementing a
normalisation procedure, and proving afterwards that this function
is correct with external lemmas. This approach is much more suitable
for programming languages like Idris. Again, this approach will be
presented in Section~\ref{sect:aSimpleProofAutomation} on the smaller problem, 
and in Sections~\ref{sect:ProvingEquivalencesInAlgebraicStructures} for the complete hierarchy of algebraic structures.

\item We develop a hierarchy of tactics where each tactic reuses the
rewriting machinery of the structure from which it naturally inherits.
For example, simplifying neutral elements is only implemented at the monoid level,
and each level inheriting from it will reuse it. Re-usability is difficult to obtain when we want to reuse the prover of a less expressive structure. For example, reusing the monoid prover for building the
group prover is not trivial, since we lose the possibility to express
negations ($-x$) and subtractions ($x-y$). Some specific encodings
will be presented in Section~\ref{sect:NormalisationsFunctionsAndReusabilityOfTheProvers} for solving this problem.

\end{enumerate}


