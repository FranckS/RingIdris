\section{Introduction}

Proofs assistants like Coq~\cite{BertotC04} 
and programming languages like 
Agda~\cite{DBLP:conf/tldi/Norell09} and
Idris~\cite{brady2013idris} are based on Intensional Type Theories that contain
two notions of equality: propositional equality, that can be
manipulated in the language, and judgemental (or definition) equality.
Propositional equality corresponds to the mathematical notion: this is
a proposition that can be assumed, negated, proved or disproved. Since in type
theory, propositions are types~\cite{How80}, the proposition that two
elements $x$ and $y$ are equal corresponds to a type.
If $x$ and $y$ are of type $a$, then the type
$Id_a(x, y)$ represents the proposition ``$x$ is equal to $y$". If this type is
inhabited, then $x$ is said to be provably equal to $y$. Thus, $Id$ is a type family (parameterised by the type $a$) indexed over two elements of $a$, giving $\code{Id} (a:\code{Type}):a \rightarrow a \rightarrow \code{Type}$. For
convenience, we write $(\code{Id}_a\ x\ y)$ as $(x\ =_a\ y)$. 

Judgemental equality, on the other hand, is a primitive concept of
the type theory.
Whether or not two expressions are judgementally equal is a matter of
evaluating the definitions. For example, if $f\ :\ \mathbb{N}\ \rightarrow\
\mathbb{N}$ is defined by $f\ x\ :=\ x\ +\ 2$, then $f\ 5$ is
definitionally equal to $7$. Definitional equality entails unfolding
of functions and reductions, until no more reduction can be
performed. We denote the definitional equality by $\equiv$.

Judgemental equality is included in propositional equality
because what is equal by definition is provably equal. This is
accomplished by giving a constructor for the type $Id(a,a)$ and no
constructor when ``$a$ is not $b$".  In these theories, $Id$ is therefore
implemented with the following type with one constructor:

\begin{lstlisting}
data Id : a $\rightarrow$ a $\rightarrow$ Type where
     Refl : (x : a) $\rightarrow$ Id x x
\end{lstlisting}

The only way for $(\code{Id}_a\ x\ y)$ to be inhabited is therefore that $x$
equals $y$. In this case, the constructor \code{Refl} helps
to create a proof of this equality: \code{(Refl\ x)} is precisely the proof
which says that $x=_ax$. 

The propositional equality does not only contain the judgemental equality,
however, because a principle of induction is associated with each inductive
type. If \code{T} is an inductive type with a constant constructor and a
recursive constructor, ie, \code{T = 1 + T}, defined in Idris as: 

\begin{lstlisting}
data T : Type where
  T0 : T
  T1 : T $\rightarrow$ T          
\end{lstlisting}

then we have the following induction principle for \code{T}: \\
$\code{T\_ind} : \forall P:\code{T} \rightarrow \code{Type},\ (P\ \code{T0}) \rightarrow (\forall t:\code{T},\ P\ t \rightarrow P\ (\code{T1}\ t)) \rightarrow (\forall t:\code{T},\ P\ t)$.

For example, we can prove that $n+0 = n$ for all $n$ by induction on the $Nat\
n$, even if $n+0 \not\equiv n$ with the usual definition of $+$, recursive on
its first argument. So, the axiom of induction means the type $Id_{a}(x,y)$
contains not only the canonical form \code{Refl}, but also those added by
inductive principles.  There are therefore things which are \emph{provably}
equal, but not \emph{definitionally} equal.  Proving equalities is therefore in
these theories something which isn't automatically decidable by the
type-checker in the general case.

\subsection{Motivating example: Verified Binary Arithmetic}
\label{sect:motivatingExample}

Proving that one term is equal to another is common in formal verification, and
proof obligations arise naturally in dependently typed programming when
indexing types over values in order to capture some logical properties.
To demonstrate this,
we revisit an example from previous work~\cite{DBLP:conf/plpv/Brady13} which
shows how proof obligations arise when a type is indexed by natural
numbers. Our goal is to implement a verified
library of binary numbers. To ensure functional correctness,
we define types \code{Bit} and \code{Binary},
indexed over the value they represent (expressed as a natural number):

\begin{lstlisting}
data Bit : Nat $\rightarrow$ Type where
     b0 : Bit Z
     b1 : Bit (S Z)
     
data Binary : (width : Nat) $\rightarrow$ (value : Nat) $\rightarrow$ Type where
     zero : Binary Z Z
     (#) : Binary w v $\rightarrow$ Bit bit $\rightarrow$ Binary (S w) (bit + 2 * v)
\end{lstlisting}

We will write a function to add two binary numbers.
To do so, we begin with an auxiliary function, which adds three bits
(the third is a carry bit), and produces the two bits of
the result, where the first is the more significant bit:

\begin{lstlisting}
addBit : Bit x $\rightarrow$ Bit y $\rightarrow$ Bit c $\rightarrow$ (bX ** (bY ** 
         (Bit bX, Bit bY, c + x + y = bY + 2 * bX)))
addBit b0 b0 b0 = (_ ** (_ ** (b0, b0, Refl)))
addBit b0 b0 b1 = (_ ** (_ ** (b0, b1, Refl)))
{- ... remaining cases follow the same pattern ... -}
\end{lstlisting}

The syntax \code{(n ** t)} denotes a \emph{dependent pair}, where the 
type of the second argument \texttt{t} can refer to the first argument
\code{n}. So, we can read this type as: ``there exists a number \code{bX},
and a number \code{bY}, such that we have two bits \code{Bit bX} and
\code{Bit bY} and the sum of the input bits \code{c}, \code{x} and
\code{y} equals \code{bY + 2 * bX}.''
For example, on the second line,
which corresponds to the computation $0_2 + 0_2 + 1_2 = (01)_2$,
the function produces this bits \code{b0} and \code{b1}, and
a proof that $0 + 0 + 1 = 1 + (2 \times 0)$.

We then define the function \code{adc} that adds two binary numbers and a carry
bit. This works for two binary numbers with the same number
of bits, and produces a result with one more bit. We would like to write:

\begin{lstlisting}
adc : Binary w x $\rightarrow$ Binary w y $\rightarrow$ Bit c $\rightarrow$ Binary (S w) (c + x + y)
adc zero zero carry = zero # carry
adc (numx # bX) (numy # bY) carry
  = let (vCarry0 ** (vLsb ** (carry0, lsb, _))) 
            = addBit bX bY carry in
        adc numx numy carry0 # lsb
\end{lstlisting}

Unfortunately, this definition is rejected because the types of each side do
not match.  The result of the first line \code{adc zero zero carry} is expected
to have the type:

\codeL{Binary\ 1\ ((c\ + 0)\ + 0)} but we provide a
term of type:

\code{Binary\ 1\ (c\ + (0\ + (0\ + 0)))}.

The problem is even worse for the second case where the expected index is:

\codeL{((c\ + (bit2\ + (v1\ + (v1\ + 0)))) + (bit\ + (v\ + (v\ + 0))))}
while we're trying to provide a term indexed over

\codeL{vLsb\ + (((vCarry0\ + v1) + v)\ + (((vCarry0\ + v1)\ + v)\ + 0))}.

The definition of \code{adc} we have given would behave correctly, and it has
\emph{provably} the expected type, but it does not have it \emph{immediately}
or \emph{judgementally}: after full reductions the expected and provided types are still
different.
If we use provisional definitions~\cite{DBLP:conf/plpv/Brady13}, the previous
definition can be accepted by the system, but we now have two proof obligations
\code{adc\_lemma\_1} and \code{adc\_lemma\_2} demanding proofs of equality
between the two types, and they have to be provided by hand.
For example, using a proof script: 

% EB - I took out a step because without the whole proof, all we really
% need to see is some representative examples of rewritings
\begin{lstlisting}
adc_lemma_2 = proof {
    intros;
    rewrite sym (plusZeroRightNeutral x);
    [...]
    rewrite (plusAssociative c (plus bit0 (plus v v)) bit1);
    rewrite plusCommutative bit1 (plus v v);
    [...]
    rewrite (plusAssociative (plus (plus x v) v1) (plus x v) v1);
    trivial;
}
\end{lstlisting}

Such proofs consist of a potentially long sequence of
rewriting steps, each using one of the properties: neutral element,
commutativity, associativity. Without some automation, this sequence of
rewritings must be done by the programmer.  Not only is this time consuming,
but a small change in the definition may lead to a different proof obligation,
thus invalidating the proof. 
A minor change in the datatype, or 
the definition of \code{addBit} or \code{adc} will require us
to do a new proof, and thus, without support from the machine, these
proofs
could become the everyday routine in any dependently-typed language.

Our handwritten proof uses only the existence of a neutral
element, and the associativity and commutativity of $+$ on \code{Nat}. Thus,
we're rewriting a term by using the properties of a commutative monoid. We
would like a generic prover for commutative monoids to find a proof 
automatically.

\subsection{Our contributions}

Provers for some algebraic structures have already been implemented for various
proof assistants, including Coq~\cite{Coq2005} and
Agda\footnote{\url{http://wiki.portal.chalmers.se/agda\%5C?n=Libraries.UsingTheRingSolver}}. 
In this paper, we describe an implementation\footnote{The
implementation of our hierarchy of tactics can be found online at
\url{https://github.com/FranckS/RingIdris/Provers}} of an automatic prover for
equalities in a \emph{hierarchy} of algebraic structures, including monoids,
groups and rings (all potentially commutative), for the Idris language.,
making the following contributions:

\begin{enumerate}

\item We present a type-safe reflection mechanism
(section~\ref{sect:typeSafeReflection}), where the reflected terms are indexed
over the concrete terms, providing a direct way to extract proofs and
guaranteeing that the reflected term is a sound representation.

\item The normalisation procedures are implemented by following a correct by
construction approach (section~\ref{sect:correctByConstruction}), instead of proving the correctness afterwards with
auxiliary lemmas. 
% This approach is much more suitable for programming languages like Idris. 

\item We develop a \emph{hierarchy} of tactics where each tactic reuses the
rewriting machinery of the structure from which it inherits.  For
example, simplifying neutral elements is implemented only at the monoid level,
and reused at other levels.
It is challenging
to reuse the prover of a less expressive structure; for
example, using the monoid prover to build the group prover is 
tricky because
we lose the ability to express negations ($-x$) and
subtractions ($x-y$). We present encodings
(section~\ref{sect:reusabilityOfTheProvers}) to overcome this problem.

\end{enumerate}

The principal novelty is in using 
\emph{type-safe reflection}.  Working by reflection for implementing tactics
has been done several times, including the implementation of a ring solver
for Coq, but without the type-safety and
correctness-by-construction. We compare our approach with other
implementations in section~\ref{sect:relatedWork}.



