\section{Introduction}


One way to increase the confidence in the software we build is to formally prove its correctness using a proof assistant. These proofs assistants enable to write code, logical statements and proofs in the same language, and offer the guarantee that every proof will be automatically checked. The appearance of these languages, and the way to write programs in them, varies from one to another. Many of them are functional programming languages, like Coq, Idris and Agda, and others, like the B-Toolkit belong to the imperative paradigm. These different paradigm are internally supported by different logic. Systems like Coq, Idris and Agda are based on various higher order logic (CoC, a variant of ML and LUO respectively) and are realisations of the Curry-Howard correspondence, while the formal B method is based on Hoare logic. These different foundations lead to different philosophies and different ways to implement and verify a software, but all of them greatly increase the confidence of the produced software. However, these guarantee tend to be too often consider as perfect, when they are in fact far from it. Knuth was --certainly ironically-- saying ``Beware of bugs in the above code; I have only proved it correct, not tried it". The reality is precisely that a proof isn't enough. When we prove the correctness of a function, we only gain the guarantee expressed by the proven lemma, and nothing more. 

Say we want to implement a formally verified sorting function that works for list of elements of type $T$, where $T$ is ordered by a relation $\leq$.
We can decide to only use a ``weak" type, like $sort\ :\ \{T:Type\}\ \rightarrow\ List\ T\ \rightarrow\ List\ T$, and to use an external lemma to ensure the correctness of the function. Which property does this function has to respect? First, the output has to be sorted. So first, we need to define this notion of being sorted, here as an inductive predicate :

\begin{lstlisting}
data isSorted : {T:Type} -> (Tord : Order T) 
                 -> (l:List T) -> Type where
    NilIsSorted : (Tord : Order T) -> isSorted Tord []
    SingletonIsSorted : (Tord : Order T) -> (x:T) -> isSorted Tord [x]
    ConsSorted : {Tord : Order T} -> (h1:T) -> (h2:T) -> (l:List T) 
                 -> (isSorted Tord (h2::t)) -> (h1 $\leq$ h2) 
                 -> (isSorted Tord (h1::(h2::t)))
\end{lstlisting}
The first and second constructor of this predicate say that $[\ ]$ and $[x]$ are sorted according to any order, and for any $x$. The third one says that a list of two or more elements is sorted if the head $h1$ is lower or equal than the next element $h2$, and if the list deprived from its head is also sorted. In order to express that the result produced by the function $sort$ is sorted, we can write and prove the following lemma:
$sort\_correct : \forall\ (T:Type)\ (l:List\ T),\ isSorted\ (sort\ l)$. The problem with this specification is that it doesn't says anything about the content of the output. The function $sort$ could just return the empty list $[\ ]$ all the time, it would still be possible to prove this correctness lemma. Here, the problem is that the function is underspecified, and it is therefore possible to write a senseless implementation, which is unfortunately provably correct. Only a careful reader could realize that the lemma $sort\_correct$ forgets to mention that the input and output list should be in bijection, meaning that everything which was originally in the input list should still be in the output, and that nothing else should have been added.

Things more nasty can happen. Imagine that the third constructor of $isSorted$, called $consSorted$ would have been written with a typo, and that the condition $(h1 \leq h2) $ would have been incorrectly written as $(h1 \leq h1)$. Then, the function $sort$ could do whatever it wants, its result would be seen as ``sorted". Said differently, any list would be seen as ``sorted" according to this predicate, just because of this single typo, and the algorithm could for example return its input unchanged. One could object that the person doing the proof of correctness should realize that the proof is being done too easily, without having to use the essential property that the output is being built such as any element in the list is always lower or equal than the next element in the list. The reality is that currently, many effort are going in the direction of proof automation, where the machine builds the proof automatically. Many proof assistants are enhanced regularly with new automations that solves automatically some kind of goals. For example, Coq has already a Ring prover~\cite{coq2005}, a solver for Presburger arithmetic, and many others automations, and Idris has been recently equipped with a hierarchy of provers for algebraics structures~\cite{Slama2016}. There are even extensions to languages, such as Ltac~\cite{DelahayeLTac} and Mtac~\cite{Ziliani13} that aim to help the automation of tactics. The problem is that the machine is never going to find a proof ``too easy", and will never report that something seems weird with the specification given by the user.

Thus, if we want to trust the proven software, we're now forced to believe that there is adequacy between the formal specification --written in some formal logic-- and the informal requirements. A switch has occurred. We used to have to trust code, but we now have to trust logical statements and predicates. But when the specification is too often as complicated as the code, why should we blindly believe in it, when we've first refused to blindly trust the code? The primary aim of this paper is to raise awareness of the adequacy concern, and to see how heterogeneous approaches, that mix both proofs and tests, can help to go a step forward in the certification process, in the context of proof assistants based on type theory.
More precisely, we :
\begin{itemize}
	\item Show some basic approaches to the problem of underspecification (section~\ref{sect:naiveApproaches})
	\item Present a way to test in the proof assistant whether the predicate effectively captures the notion that we wanted to define, by automatically generating terms, and we automate these tests as far as possible (section~\ref{sect:testingInside})
	\item Present how we can go a step forward by replacing these tests about the predicate by some proofs (section~\ref{sect:aStepForward})
\end{itemize}

We use Idris~\cite{brady2013idris}, a dependently typed programming language that can also be seen as a proof assistant, but all the ideas that we present here can be applied to any proof assistant based on type theory.

