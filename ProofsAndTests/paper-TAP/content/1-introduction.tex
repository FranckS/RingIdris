\section{Introduction}

There are multiple ways for increasing confidence in the software we build. One of them is to formally prove its correctness, using a proof assistant. These proofs assistants enable to write code, logical statements and proof in the same language, and offer the guarantee that every proof will be automatically checked. The appearance of these languages, and the way to write programs in them, varies from one to another. Many of them are functional programming languages, like Coq, Idris and Agda, and others, like the B-Toolkit belong to the imperative paradigm. These different paradigm are internally supported by different logic. Systems like Coq, Idris and Agda are based on various higher order logic (CoC, a variant of ML and LUO respectively) and are realisations of the Curry-Howard correspondence, while the formal B method is based on Hoare logic. These different foundations lead to different philosophies and different ways to implement and verify a software, but all of them greatly increase the confidence of the produced software. However, these guarantee tend to be too often consider as perfect, when they are in fact far from it. Knuth was --certainly ironically-- saying ``Beware of bugs in the above code; I have only proved it correct, not tried it". The reality is precisely that a proof isn't enough. When we've proved the correctness of a software, we've only gained the guarantee expressed by the proven lemma, and nothing more. Thus, if we want to trust the proven software, we're now forced to believe that there is adequacy between the formal specification, written in some formal logic, and the informal requirements. A switch has occurred. We used to have to trust code, but we now have to trust logical statements and predicates. But when the specification is too often as complicated as the code, why should we blindly believe in it, when we've first refused to blindly trust the code? Too few people realize that the proving activity has created this silent assumption of adequacy between the formalised specification and the original real requirements, usually written in english. Of course, the proving activity has undeniably increased the confidence in the produced software, and the aim of this paper isn't to say otherwise. Many successful applications of these formal methods [CompCert ref, etc] have showed the value of developing a machined-checked proof of correctness. Instead, the primary aim of this paper is to raise awareness of the adequacy concern, and to see how heterogeneous approach, that mix both proofs and tests, can help to go a step forward in the certification process, in the context of proof assistants based on type theory.
More precisely, we :
\begin{itemize}
\item Show how a formal specification can be wrong or under specified, leading to a proof that does not convey the expected guarantee, and the usual and naive approaches to this problem (section 2)
\item Show the distinction between structural properties, and the properties on the content, and how to identify what needs to be tested for the former category (section 3).
\item Show how to conduct these tests in the proof assistant itself, by automatically generating terms, and how to automate these tests as far as possible (section 4)
\end{itemize}

We will use Idris~\cite{brady2013idris}, a dependently typed programming language that can also be seen as a proof assistant, but all the ideas that we present here can be applied to any proof assistant with dependent types.


\


To add in the intro :

- Many companies doing critical software don't believe in 
(one sentence)




