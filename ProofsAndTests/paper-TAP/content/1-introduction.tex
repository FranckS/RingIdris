\section{Introduction}


One way to increase the confidence in the software we build is to formally prove its correctness using a proof assistant. Proofs assistants enable to write code, logical statements and proofs in the same language, and offer the guarantee that every proof will be automatically checked. Many of them are functional programming languages, like Coq, Idris and Agda, and others, like the B-Toolkit belong to the imperative paradigm. These different paradigms are internally supported by different logic. Systems like Coq, Idris and Agda are based on various higher order logics (CoC, a variant of ML and LUO respectively) and are realisations of the Curry-Howard correspondence, while the formal B method is based on Hoare logic. These different foundations lead to different philosophies and different ways to implement and verify a software, but all of them greatly increase the confidence of the produced software. However, these guarantees tend to be too often considered as perfect, when they are in fact far from it. Knuth was --certainly ironically-- saying ``Beware of bugs in the above code; I have only proved it correct, not tried it". The reality is precisely that a proof is not enough. When we prove the correctness of a function, we only gain the guarantee expressed by the proven lemma, and nothing more. 

Say we want to implement a formally verified sorting function for list of elements of type $T$, where $T$ is ordered by a relation $\leq$.
We can decide to define the sorting function with a ``weak" type, like $sort\ :\ List\ T\ \rightarrow\ List\ T$, and to use an external lemma to ensure the correctness of the function. Which property does this function has to respect? First, the output has to be sorted, so we need to define this notion of being sorted, here as an inductive predicate :

\begin{lstlisting}
data isSorted : {T:Type} -> (Order T) -> (List T) -> Type where
    NilIsSorted : (Tord : Order T) -> isSorted Tord []
    SingletonIsSorted : (Tord : Order T) -> (x:T) -> isSorted Tord [x]
    ConsSorted : {Tord : Order T} -> (h1:T) -> (h2:T) -> (t:List T) 
                 -> (isSorted Tord (h2::t)) -> (h1 $\leq$ h2) 
                 -> (isSorted Tord (h1::(h2::t)))
\end{lstlisting}
The first and second constructor of this predicate say that $[\ ]$ and $[x]$ are sorted according to any order, and for any $x$. The third one says that a list of two or more elements is sorted if $h1 \le h2$, and if the list deprived from its head is also sorted. In order to express that the result of $sort$ is sorted, we can prove the following lemma:
$sort\_correct : \forall\ (T:Type)\ (Tord:Order\ T)\ (l:List\ T),\ isSorted\ Tord\ (sort\ l)$. The problem with this specification is that it does not say anything about the content of the output. The function $sort$ could just return the empty list $[\ ]$ all the time, it would still be possible to prove this correctness lemma. Here, the problem is that the function is underspecified, and it is therefore possible to write a senseless implementation, which is unfortunately provably correct. Only a careful reader could realise that the lemma $sort\_correct$ forgets to mention that the input and output list should be in bijection, meaning that everything which was originally in the input list should still be in the output, and that nothing else should have been added.

Another bug in the specification could have been to simply forget the third constructor $ConsSorted$. But things more nasty can happen. Imagine that the third constructor of $isSorted$, called $consSorted$ would have been written with a typo, and that the condition $(h1 \leq h2) $ would have been incorrectly written as $(h1 \leq h1)$. Any list would be seen as ``sorted", just because of this single typo, and the algorithm could for example return its input unchanged. One could object that when doing the proof of correctness, we should realize that the proof is being done too easily, without having to use the essential property that the output is being built such as any element in the list is always lower or equal than its next element. The reality is quite different because many effort are going in the direction of proof automation, which aims to let the machine generate automatically the proof for some kind of goals. For example, Coq has already a Ring prover~\cite{coq2005} and many others automations, and Idris has been recently equipped with a hierarchy of provers for algebraics structures~\cite{Slama2016}. There are even extensions to languages, such as Ltac~\cite{DelahayeLTac} and Mtac~\cite{Ziliani13} that aim to help the automation of tactics. The problem is that the machine is never going to find a proof ``too easy", and will never report that something seems weird with the specification given by the user.

Thus, if we want to trust the proven software, we're now forced to believe that there is adequacy between the formal specification and the informal requirements. A switch has occurred. We used to have to trust code, but we now have to trust logical statements and predicates. But when the specification is too often as complicated as the code, why should we blindly believe in it, when we've first refused to blindly trust the code? The primary aim of this paper is to raise awareness of the adequacy concern, and to see how heterogeneous approaches, that mix both proofs and tests, can help to go a step forward in the certification process, in the context of proof assistants based on type theory.
More precisely, we :
\begin{itemize}
	\item Show some basic approaches to the problem of underspecification (section~\ref{sect:naiveApproaches})
	\item Present a new way to test the predicate in the proof assistant, by automatically generating terms, and we completely automate these tests (section~\ref{sect:testingInside})
	\item Present how we can go a step forward by replacing these tests about the predicate by some proofs (section~\ref{sect:aStepForward})
\end{itemize}

We use Idris~\cite{brady2013idris}, a dependently typed programming language, but all the ideas that we present here can be applied to any proof assistant based on type theory.

