\section{Normalisation functions and Reusability of Provers}

\label{sect:reuse}

We now describe briefly how the normalisation functions work for some of the different algebraic structures, and we also explain how we've been able to reuse each prover for the more specialised structures. The construction of the desired proof is always done bit by bit, because every rewriting of the reflected term is immediately justified by a little accompanying proof which shows the equivalence of the previous and new index.
\begin{figure}[H]
\figrule
\begin{center}
\begin{lstlisting}
littleRewriting : (p:algebraic structure on c) $\rightarrow$ ($\Gamma$:Vect n c) 
       $\rightarrow$ {c1:c} $\rightarrow$ (Expr p $\Gamma$ c1) $\rightarrow$ (c2 ** (Expr p $\Gamma$ c2, c1 $\simeq$ c2))
littleRewriting p $\Gamma$ e = (new expression, justification)
\end{lstlisting}
\end{center}
\caption{General pattern of a function doing a part of the normalisation}
\figrule
\end{figure}

	\subsection {Normalization of terms in a Semi-Group}
In a semigroup, we only have to deal with the property of associativity. As it was the case with the toy example in section 2, we will have to rearrange the parenthesis on a systematic way, either left associative, or right associative. But this is not the only thing that we have to do. If $x$, $y$ and $z$ denote variables, we don't only want to transform $x+((y+4)+(5+z))$ into $(((x+y)+4)+5)+z$ --we assume we've chosen the complete left associative form--. We also want the constants $4$ and $5$ to be simplified together, because they are close to each other (and we have the right to do so because we can rearrange the parenthesis thanks to the associativity), and the result should be $((x+y)+9)+z$ on this example. Three possible patterns need this treatment : $(x+const1)+(const2+y)$, $(x + const1) + const2$  and $const1 + (const2 + x)$ where $const1$ and $const2$ denote constants. The simplification between the constants $const1$ and $const2$ is denoted here as $[const1+const2]$, and this computation can be done at the underneath $Magma$ level, with its normalisation function called $magmaReduce$.
The first pattern is rewritten into $(x + [const1+const2]) + y$, the second into $(x + [const1+const2])$ and the third one into $([const1 + const2] + x)$.
We show the code for the first pattern.

\begin{figure}[H]
\figrule
\begin{center}
\begin{lstlisting}
assoc : (p:SemiGroup c) $\rightarrow$ ($\Gamma$:Vect n c) $\rightarrow$ {c1:c} 
        $\rightarrow$ (ExprSG p $\Gamma$ c1) $\rightarrow$ (c2 ** (ExprSG p $\Gamma$ c2, c1 $\simeq$ c2))
assoc p $\Gamma$ (PlusSG 
             (PlusSG ex (ConstSG _ _ const1)) 
             (PlusSG (ConstSG _ _ const2) ey)) =
    let (r_ihx ** (e_ihx, p_ihx)) = (assoc p $\Gamma$ ex) in
    let (r_ihy ** (e_ihy, p_ihy)) = (assoc p $\Gamma$ ey) in
    let (r_3 ** (e_3, p_3)) = magmaReduce (semiGroup_to_magma 
                             (PlusSG (ConstSG _ _ const1) (ConstSG _ _ const2))) in
    let e_3' = magma_to_semiGroup p e_3 in
        (_ ** ((PlusSG (PlusSG e_ihx e_3') e_ihy), ?Massoc1))
\end{lstlisting}
\end{center}
\caption{Computing with associativity in a Semi-Group, first pattern}
\figrule
\end{figure}
The treatment is applied recursively on the sub-expressions $ex$ and $ey$, which produces the new expressions $e\_ihx$ and $e\_ihy$ together with the new concrete values they represent ($r\_ihx$ and $r\_ihy$) and the proofs ($p\_ihx$ and $p\_ihy$) justifying these transformation on the concrete values. Note that the simplification $[const1+const2]$ is done by calling the magma prover, which gives a new expression $e3$, even thought it could perfectly be done directly here, but we wanted to show how a prover can be reused for building another prover on an easy example. The functions of conversion between the different levels : $semiGroup\_to\_magma$ and $magma\_to\_semiGroup$ are helping for this task.
\\
A meta-variable Massoc1 has been introduced. This metavariable corresponds to a proof obligation for the following property :
$Massoc1 : Plus\ (Plus\ x\ const1)\ (Plus\ const2\ y)\ \simeq\ Plus\ (Plus\ r\_ihx\ r_3)\ r\_ihy$ in a context where there is, amongst other things, $p\_ihx : x\ \simeq\ r\_ihx$, $p\_ihy : y\ \simeq\ r\_ihy$ and $p_3 : Plus\ const1\ const2 \simeq r\_3$.
This lemma says that the treatment done by this function $assoc$ on this pattern was sound because the previous and the new concrete values are equal. It can easily be proven with a few rewritings and the use of the associativity, available from the semi-group structure. \\
\\
After this simplification of constants computable thanks to associativity, the normalization for SemiGroup also has to rearrange the brackets on a systematic way. The fully right or fully left associative forms can both be chosen for this purpose, and the implementation is very similar to the function $expr_l$ previously described for the smaller example on section 2.3.

\subsection {Reusing the semigroup prover for building the monoid prover}

In a monoid, we simply have to eliminate zeros, thanks to the two properties of left and right neutrality. Because the simplification of additions between a zero and another constant has already be done at the level of semigroup (by computing the addition of these two constants), we only have to simplify the addition between the constant zero and a variable. There is in fact two cases, since the variable can come first, or the $Zero$ can come first. We can write a function $elimZero$ which rewrites these two patterns $x+Z$ and $Z+x$ into $x$.


The normalization of reflected expressions in a monoid is simply made of a call to the function reducing terms on a semigroup, followed by a call to elimZero that will eliminates the remaining additions with zeros. 




The first thing that the reduction function of the group prover will have to do is simply to transform every subtraction $(a-b)$ into $(a + (-b))$, and we are entitled to do so precisely because we have available the property $Minus\_simpl$ contained in the instance of the type class.
After that, the reduction continues with the propagation of the $Neg$ operation inside the parenthesis and $-(a+b)$ is transformed into $(-b) + (-a)$. Note that we have to be careful and not simplify it to $(-a) + (-b)$ as it would assume that we're having a commutative monoid.
Then, because we've pushed some negations inside the parenthesis, we might have sequences of two or more consecutive negations. We simplify them by removing two consecutive negations every time that we find such a sequence. Once this is done, there is a last major step specific of groups to accomplish, which is the simplification of sums of symmetric elements. 

This might be a direct sum of symmetric elements, like $-e1 + e2$ or $e1 + -e2$ and in these two cases, we need to simplify them when $e1$ can be reduced\footnote{It is not enough to simply check their syntactical equality, as they might not be immediately equal but could perhaps be normalised to the same term. Thus, this step --which is part of the reduction function-- uses the entire reduction function, but it calls it on a smaller term} to $e2$ , and if so the result should be $Zero$. We are entitled to do this treatment because of the property $Plus\_inverse$.

The sum to simplify might be more complex, with two or three levels of of $Plus$. In these cases, there might be some simplifications to do thanks to the associativity property. With two levels of sums, we will transform $(e1 + (-e2 + e3))$ and $(-e1 + (e2+e3))$ into $e3$ when $e1$ can be reduced to $e2$. Also, $((e1+e2) + -e3))$ and $((e1+(-e2)) + e3)$ are simplified into $e1$ when $e2$ can be reduced to $e3$. Finally, in presence of three level of sums, we will transform $(a+b) + ((-c)+d)$ and $(a+(-b)) + (c+d)$ into $a+d$ when $b$ can be reduced to $c$.

The last remaining step is to call the monoid prover. Unfortunately, we can't directly write a function of conversion from group to monoid, because in a group we have the possibility to express negations and subtractions, that we do not have in a monoid. The idea is that we will encode negations as variables, and we will let the monoid prover deal with them as ordinary variables. In order to achieve this goal, we need the following datatype :


\begin{figure}[H]
\figrule
\begin{center}
\begin{lstlisting}
data Variable : {c:Type} -> {n:Nat} -> (Vect n c) -> c -> Type where
    RealVariable : ($\Gamma$:Vect n c) -> (i:Fin n) -> Variable $\Gamma$ (index i $\Gamma$)
    EncodingNegOfVar : ($\Gamma$:Vect n c) -> (i:Fin n) -> Variable $\Gamma$ (Neg (index i $\Gamma$))
\end{lstlisting}
\end{center}
\caption{Real variables and encodings}
\figrule
\end{figure}

We only need to encode negations of variables, as negations of constants can be simplified into a constant. Also, there can't be a negation of something more complicated than an atom (a variable or a constant), because of the treatments we've done beforehand, especially because we've propagated all the negations symbols inward the parenthesis.

The constructor for variable now takes a Variable, instead of taking directly a $(Fin\ n)$.
\begin{figure}[H]
\figrule
\begin{center}
\begin{lstlisting}
    VarG : (p:Group c) -> {$\Gamma$:Vect n c} -> {val:c} 
          -> (Variable $\Gamma$ val) -> ExprG p $\Gamma$ val
\end{lstlisting}
\end{center}
\caption{new Var constructor}
\figrule
\end{figure}

Thanks to this encoding, we can now transform an $ExprG$ to an $ExprMo$. A constant $(ConstG\ p\ \Gamma\ c1)$ will be transformed into the corresponding constant $(ConstMo\ p\ \Gamma\ c1)$, a $PlusG$ into the corresponding $PlusMo$, a variable $(VarG\ p\ var)$ into the corresponding variable $(VarMo\ p\ var)$, the negation of a constant into the resulting constant, and finally the negation of a variable $i$ into a $(Var\ p\ \Gamma\ (EncodingNegOfVar\ \Gamma\ i))$.
Once this encoding is computed, the antepenultimate step is to call the monoid prover and to let it finish the normalisation. Finally, we need to convert back the result into an $ExprG$ by interpreting the $EncodingNegOfVar$ into a $Neg$ of the corresponding variable.


\subsection {Reusing the group prover for building the commutative group prover}

The normalisation of the commutative group prover starts by calling the group prover. Here, the two algebraic structures have the same power of expressivity, and thus there's no specific encoding to design. Then, we simply need to decide an ordering for variables and constants. We arbitrary decide that $Var\ FZ\ <\ Var\ (FS\ FZ)\ <\ Var\ (FS\ (FS\ FZ))\ <\ ...\ <\ Constant$. The normalisation function will therefore simply sort the expression with this ordering and will do basic simplifications.



\subsection {Reusing the commutative group prover for building the ring prover}

The most important specific task of the ring reduction is to develop entirely the expression with the use of distributivity. After that, it needs to call the commutative group prover, but again, we're losing some expressivity as it won't be possible to express a product at the commutative group level. We follow the same idea that we've implemented for the conversion going from group to monoid, and we will use some specific encoding. More precisely, all monomials (containing products), like $3*(x*y)$ are encoded as variables when passed to the commutative group prover. This is possible because we've fully developed the expression, which had for effect to ensure that a product can't contain a sum.
We will add a coonstructor to the type $Variable$ in order to encode these monomials.



