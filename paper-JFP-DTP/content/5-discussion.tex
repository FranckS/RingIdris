\section {Discussion}


	\subsection{Comparison with a traditional approach}

Without our type-safe reflection mechanism, the traditional way to go for this problem would be to have functions doing only computations, and some external lemmas about them. It would start with the definition of the function $reify\ :\ Expr\ \rightarrow\ c$. As we did in our approach, there is still a function for reflecting terms $reflect\ :\ c\ \rightarrow\ Expr$. Because $reflect$ is a function based on syntax,  the actual way to define depends on the facilities of the proof assistant / programming language used, but there need to be a way to write functions based on syntax. We need to prove the correctness of these two functions, and it turns out that one lemma is enough for completely specifying the expected behaviour of these two functions at the same time : $reflect\_and\_reify\_correct\ :\ \forall\ x:c,\ reify\ (reflect\ x)\ =\ x$.

Then comes the normalisation function : $normalize\ :\ Expr\ \rightarrow\ Expr$. Because this function is weekly typed compared to our approach (we no longer have an index giving a guarantee about the concrete values), we need to provide a lemma of correctness about it after its definition. This lemma of correctness must say that the interpretation of the original (reflected) term is equal to the interpretation of the normalised (reflected) term. $normalize\_correct\ :\ \forall\ e:Expr,\ reify\ (normalize\ e)\ =\ reify\ e$. We have avoided the need of such a --complicated-- proof in our correct by construction approach enabled by our type-safe reflection mechanism.

Now, similarly to what we've done, we need a syntactical equality test, checking whether two reflected expressions are syntactically equal. The difference here is that, as often with this kind of "traditional" approach, we produce something that belongs to the world of computations, usually a (pretty uninformative) boolean.
$beq_{Expr}\ :\ Expr\ \rightarrow\ Expr\ \rightarrow\ bool$. Because this boolean on its own is pretty uninformative, we now need a proof of correctness for this function as well, which says that if this function decides that two given terms are syntactically equal, then their interpretation should also be (syntactically) equal. $beq_{Expr}\_correct\ :\ \forall (e1\ e2:Expr), beq_{Expr}\ e1\ e2\ =\ true\ \rightarrow\ reify\ e1\ =\ reify\ e2$. We did not have to do this proof either with our approach.

We now build the kernel of the tactics, which is the following decision procedure. 
\begin{figure}[H]
\figrule
\begin{center}
\begin{verbatim}
decideEq : c -> c -> bool 
decideEq x y =
      let xRefl = reflect x in 
      let yRefl = reflect y in
      beq_Expr (normalise xRefl) (normalise yRefl)
\end{verbatim}
\end{center}
\caption{Decision procedure of the tactic with a "traditional" approach}
\figrule
\end{figure}
This function on its own is not going to be enough. We need to add it a correctness theorem, and this is precisely this main theorem which is going to help us build the tactic we want.	
$decideEq\_correct\ :\ \forall\  x\ y:c,\ decideEq\ x\ y\ =\ true\ \rightarrow\ x\ =\ y$. This proof can be made by combining, in this order, the three lemmas $beq_{Expr}\_correct$, $normalize\_correct$ (two times, one on each side of the assumed equality), and finally $reflect\_and\_reify\_correct$ (again two times).

Now, the tactic can be build by using this correctness theorem. When trying to prove a goal $a\ =\ b$, the tactic will apply this theorem $decideEq\_correct$, which means that $x$ will be unified to $a$ and $y$ to $b$. The desired proof is thus produced if the premise $decideEq\ a\ b\ =\ true$ holds. But whether this premise holds or not can simply be tested by running the function $decideEq$ on the two arguments $a$ and $b$. 

Both with this "traditional" approach and with our type-safe reflection, the activity of proving has effectively been replaced by the task of running a function, and a simple evaluation is now enough to produce the desired proof. The main advantage of our approach compared to this kind of traditional approach is that we don't need external lemmas, and more generally that the proof of correctness is obtained a lot more easily. Let's now see the differences more precisely with an actual implementation that almost follows the paradigm of the traditional approach.

	\subsection {Comparison with Coq's approach}
	
In Coq's latest implementation of a Ring solver, described in [1], they almost followed what has just been desribed as a "traditional" approach with the use of many auxiliary lemmas. The few differences essentially lie in the way the function $reflect$ is defined. In Coq, they use the language LTac to program this automatic reflection\footnote{This function --that they call mkPolexpr-- can be found in $plugins/ring/Ring\_tac.v$}. Ltac is an untyped tactic language. It is untyped in the sense that an Ltac "function" produces something which might not have a valid  --and unique-- type. Because of this, Ltac definitions can only be used in the context of goals. Thus, applying a tactic defined with LTac might work, and then it makes progress to the current goal, or it might fail, and in this case the goal is kept unchanged. And anyway, the safety of the proof done is going to be checked during the final QED. So, Ltac functions can't be used in the statement of a lemma, and it is therefore not possible to reason about them. That means that it is not possible to write the lemma $reflect\_and\_reify\_correct$ of the "traditional" approach described in the previous subsection, because it is even impossible to state it as it uses a function defined in LTac. Because they can't even state this property, they can't finish the proof of the main theorem $decideEq\_correct\ :\ \forall\  x\ y:c,\ decideEq\ x\ y\ =\ true\ \rightarrow\ x\ =\ y$. Indeed, the last step of this proof was to apply two times --one for the LHS, one for the RHS-- the fact that $\forall\ x:c,\ reify\ (reflect\ x)\ =\ x$. One possibility would have been to add this axiom, but this is particularly unsightly, and potentially harmful. Also, it would imply that anyone using the ring prover would have this axiom added to his development, and would be forced to believe in it. Some proofs would be done automatically for the user of the system, but at the overly-expensive price of adding some uncertainty.
Instead, what they did for Coq's implementation of the Ring prover is to replace the main theorem $\forall\  x\ y:c,\ decideEq\ x\ y\ =\ true\ \rightarrow\ x\ =\ y$ by the following weaker --but still powerful enough to build the desired tactic-- lemma\footnote{This lemma --that they call $setpolynomial\_simplify\_ok$ can be found in $plugins/ring/Setoid\_ring\_normalize.v$}  : $f\_correct\ :\ \forall\ (e1\ e2\ :\ Expr),\ beq_{Expr}\ (norm\ e1)\ (norm\ e2)\ =\ true\ \rightarrow\ reify\ e1\ =\ reify\ e2$.
Now, the tactic works like this. When trying to prove the goal $a=b$, it computes $(reflect\ a)$ and $(reflect\ b)$. It then tries to apply $(f\_correct\ (reflect\ a)\ (reflect\ b))$ to the goal. 
\itemize
\item
If it can unify the goal $a=b$ with $reify\ (reflect\ a)\ =\ reify\ (reflect\ b)$ then it only has to check the validity of the premise by running the decision procedure. More precisely, if $beq_{Expr}\ (norm\ (reflect\ a))\ (norm\ (reflect\ b))$ is evaluated to $true$, then it has built the premise of $f\_correct$ and there's nothing left to prove. However, if the result was false, then it means that the automatic ring prover hasn't been able to prove this goal, because the LHS and RHS don't reduce to the same thing. If this ring prover is complete, it means that $a$ is not\footnote{Note that in this case, it hasn't produced such a formal proof of disequality, which isn't the goal of a ring prover} equal to $b$, or at least, they aren't equal only with the properties of a ring.
\item
if it couldn't unify the goal $a=b$ with $reify\ (reflect\ a)\ =\ reify\ (reflect\ b)$, then it means that there is something wrong in the definitions of the functions $reflect$ and $reify$, and it could print something like "The ring prover has failed unexpectedly. There's something wrong with the implementations of the $reflect$ and $reify$ functions". Nothing really bad happened, as no inconsistent proof has been produced, nor no axioms added. That would just mean that the implementation of the ring prover is slightly broken, and that some goals that should be automatically provable aren't automatically proved. Thus, it would only decrease the completeness of the prover. That would be of course bad --because in the extreme case, the prover never succeed in a generating a proof and is thus completely useless--, but that would only limit the scope of usage of the prover.

	\subsection {Correctness and completeness}

		\subsubsection{Correctness}
		
The correctness of the tactic is in fact obtained by construction. Actually, what we really needed was to produce the proof of the equality $a=b$, and not the normalised terms. The normalised term --and more precisely their construction-- was just a support for building the desired proof of $a=b$, which is precisely the proof of correctness. Thus, there isn't any possibility that we've generated a wrong proof as long as we ensure that :
\begin{itemize}
\item We haven't introduced any axioms
\item We haven't introduced any non total\footnote{Contrary to Coq, Idris allows the definition of non-total functions for helping the development of non-finished real-world projects} function or proof used for the building of the main proof $a=b$. Note that the normalization itself could contain some non total functions without breaking the correctness. That would just mean that when using this tactic, the tactic could loop infinitely and the user would never get his answer. That would of course be bad, but that would not produce any inconsistency --as long as none uses these definitions maliciously to prove something false--, because this non total function would be only used in the world of computations and not in the world of logic.
\end{itemize}

Because we've meet these two conditions, we simply can't produce a false proof of a statement, because the typechecker would complain if that would be the case. If Idris internal type tyeory is consistent, then one can't produce a false lemma without either introducing an axiom nor introducing a non total function and latter using it to create inconsistencies in the logic.

		
		\subsubsection{Completeness}
		
Completeness means that when given an equality which is provable by using the properties of the concerned algebraic structure, the prover should be able to generate a proof of this equality. Having a complete tactic is important, because otherwise the tactic is not always usuable -- and in the worst case it is never usable--, and thus is not valuable. However, having a formal proof of the completeness in the system itself isn't really interesting. As long as we do not meet an equality that should be provable, and which isn't proved by our tactic, there is no problem. And if this situation does happen, nothing really bad really happened : no inconsistencies have been introduced in the system. The tactic just refuses to do it automatically for the programmer. The user can still attempt it. \\

If we believe that the normal form computed by the reduction function is indeed a normal form --which means that if two terms are equal according to the properties of an algebraic structure, then their normal form should be equal-- then the tactic is complete.
Indeed, 
$meta\_propetry\ :\ \forall\ a\ b,\ a=b \rightarrow norm\ (reflect\ a) = norm\ (reflect\ b)$ is equivalent to

$completeness : \ \forall\ a\ b,\ norm\ (reflect\ a) \neq norm(reflect\ b) \rightarrow a \neq b$, which is in fact :
$\ \forall\ a\ b,\ decideEq\ (reflect\ a)\ (reflect\ b) = Nothing \rightarrow a \neq b$. The equivalence between $meta\_property$ and $completeness$ can only be done in the meta theory because it is a proof by contradiction, which is equivalent to the law of excluded middle, that we do not have in constructive logics, on which Idris is based.

Question : Does $completeness$ is provable in the system ? Would it be doable for the little example with natural numbers for example ? I want to know if it's something improvable in the theory itself (and in this case why, precisely!), or just something really hard ?
Anyway, it has never been done for this problem (not for Coq's ring prover, nor for Agda's ring prover). Can I do it for the little example with natural numbers though ? \\

Another little advantage of our approach, compared to Coq's approach, is that we have the guarantee that we can't lose any totality because of the $reflect$ function. The reason is that the produced reflected term is indexed over the original --concrete-- value. By this fact, we don't need a $reify$ function. If we want to go from the reflected term to the original --concrete-- value, we can simply return the index. Thus, we have the guarantee that $(reflect\ a)$ is always a faithful representation of $a$ with our approach. Coq's approach doesn't have this guarantee, and could potentially lose some completeness if this property is not always true, as mentioned earlier during the comparison with Coq's implementation.